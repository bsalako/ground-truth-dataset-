# ground-truth-dataset for GRC & AI Governance
A structured, framework‑aligned ground truth dataset designed to evaluate AI systems on Governance, Risk & Compliance (GRC) and AI Governance tasks.
This repository includes authoritative answers, evidence requirements, framework mappings, risk classifications, and acceptable variations for 25+ evaluation questions.

This project demonstrates practical, hands‑on AI governance work, including dataset design, evaluation methodology, and governance documentation.
